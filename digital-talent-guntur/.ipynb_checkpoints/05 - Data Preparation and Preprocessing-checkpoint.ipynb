{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Missing Value\n",
    "\n",
    "Sering kali, data rusak, atau hilang, kita perlu mengurusnya terlebih dahulu karena kedepannya data ini tidak berfungsi saat data hilang atau tidak lengkap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing missing values dengan Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop kolom spesifik yang mengandung NaN \n",
    "df.dropna(subset=['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:, 1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace every occurrence of missing_values to one defined by strategy\n",
    "# which can be mean, median, mode. Axis = 0 means rows, 1 means column\n",
    "\n",
    "imputer = Imputer(missing_values='NaN', strategy='mean', axis = 0)\n",
    "df.iloc[:, 1:3] = imputer.fit_transform(df.iloc[:, 1:3])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Encoding Data Kategori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoder will replace every categorical variable with number. Useful for replacing yes by 1, no by 0.\n",
    "# One Hot Encoder will create a separate column for every variable and give a value of 1 where the variable is present\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lable_encoder = LabelEncoder()\n",
    "temp = df.copy()\n",
    "temp.iloc[:, 0] = lable_encoder.fit_transform(df.iloc[:, 0])\n",
    "print(lable_encoder.classes_)\n",
    "temp.iloc[:, 3] = lable_encoder.fit_transform(df.iloc[:, 3])\n",
    "print(lable_encoder.classes_)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can pass an array of indices of categorical features\n",
    "# one_hot_encoder = OneHotEncoder(categorical_features=[0])\n",
    "# temp = df.copy()\n",
    "# temp.iloc[:, 0] = one_hot_encoder.fit_transform(df.iloc[:, :0])\n",
    "# temp\n",
    "# you can achieve the same thing using get_dummies\n",
    "pd.get_dummies(df.iloc[:, :-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Binarizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mengubah Data menjadi 0 dan 1.\n",
    "Kita akan mencoba dataset lain, yaitu dataset iris yang ada pada library scikit-learn. (https://archive.ics.uci.edu/ml/datasets/iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_dataset = load_iris()\n",
    "X = iris_dataset.data\n",
    "y = iris_dataset.target\n",
    "feature_names = iris_dataset.feature_names\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita akan mengubah 0 jika dibawah rata-rata, dan 1 jika diatas rata-rata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "binarizer_obj = Binarizer(threshold=X[:, 1].mean())\n",
    "X[:, 1:2] = binarizer_obj.fit_transform(X[:, 1].reshape(-1, 1))\n",
    "X[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Fitur Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, MinMaxScaler\n",
    "\n",
    "df = pd.read_csv('Data.csv').dropna()\n",
    "print(df)\n",
    "X = df[[\"Age\", \"Salary\"]].values.astype(np.float64)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = StandardScaler()\n",
    "normalizer = Normalizer()\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "print(\"Standardization\")\n",
    "print(standard_scaler.fit_transform(X))\n",
    "\n",
    "print(\"Normalizing\")\n",
    "print(normalizer.fit_transform(X))\n",
    "\n",
    "print(\"MinMax Scaling\")\n",
    "print(min_max_scaler.fit_transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Ekstraksi Fitur\n",
    "Pada pertemuan sebelumnya kalian telah mencoba membuat program WordCount. WordCount merupakan sebuah teknik dalam melakukan ekstraksi Fitur. Namun, kalian tidak perlu membuat sendiri. Scikit-Learn telah menyediakan librarynya. Ekstraksi Fitur ini nantinya akan berguna dalam pemrosesan klasifikasi, clustering, maupun teknik pembelajaran mesin lainnya.\n",
    "## 5.1 Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "docs = [\"Mayur mayur is a nice boy.\", \"Mayur rock! wohooo!\", \"My name is Mayur, and I am a Pythonista!\"]\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(docs)\n",
    "print(X)\n",
    "print(cv.vocabulary_)\n",
    "print(X.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dict Vectorizer\n",
    "\n",
    "DictVectorizer melakukan mapping dari dictionry wordcount ke Vektor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "docs = [{\"Aku\": 1, \"suka\": 1, \"makan\": 2}, {\"Aku\": 1, \"tidak\": 1, \"suka\": 2, \"makan\": 3, \"kambing\": 1, \"bakar\": 2, \"madu\": 3}]\n",
    "dv = DictVectorizer()\n",
    "X = dv.fit_transform(docs)\n",
    "print(X)\n",
    "print(dv.vocabulary_)\n",
    "print(X.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfIdf Vectorizer:\n",
    "Word Count (Term Frekuensi dikali dengan Inverse Dokumen Frekuensi),\n",
    "\n",
    "Tutorial dapat dilihat pada link berikut:\n",
    "https://datascience.mipa.ugm.ac.id/id/representasi-teks-dalam-vektor-part-1/\n",
    "https://datascience.mipa.ugm.ac.id/id/representasi-teks-dalam-vektor-part-2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "cv_vectorizer = CountVectorizer()\n",
    "docs = [\"Mayur is a Guitarist Guitarist\", \"Mayur is Cooker\", \"Mayur is Musician\", \"Mayur is also a programmer\"]\n",
    "X_idf = tfidf_vectorizer.fit_transform(docs)\n",
    "X_cv = cv_vectorizer.fit_transform(docs)\n",
    "print(X_idf.todense())\n",
    "print(tfidf_vectorizer.vocabulary_)\n",
    "print(X_cv.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GROUP PROJECT\n",
    "\n",
    "Tujuan dari Project ini adalah mengaplikasikan hal-hal yang telah dipelajari dari setiap pertemuan pada Digital Talent pada sebuah \"big dataset\" yang dipilih hingga akhirnya menemukan \"insight\" dari data tersebut.\n",
    "\n",
    "Grup Terdiri dari 4-5 orang, dan akan dipilihkan oleh pengajar secara acak.\n",
    "\n",
    "Dataset yang digunakan adalah GDELT Dataset (Tentatif) https://www.gdeltproject.org\n",
    "\n",
    "\n",
    "Terdapat milestone yang harus dilaporkan setiap minggunya dalam bentuk Pdf:\n",
    "\n",
    "Milestone 1 : \n",
    "- Deskripsi Project & Dataset. \n",
    "- Eksplorasi Data\n",
    "\n",
    "Milestone 2 : \n",
    "- Eksplorasi dengan Statistik Deskriptif\n",
    "- Research Question\n",
    "\n",
    "Milestone 3 :\n",
    "- Model Pembelajaran Mesin yang mungkin diterapkan\n",
    "- Dasar Pemilihan Metode\n",
    "\n",
    "Milestone 4 :\n",
    "- Pembahasan Mengenai Hasil dari riset yang telah dilakukan\n",
    "- Visualisasi Data dengan Tools yang diajarkan\n",
    "\n",
    "\n",
    "Milestone 5 :\n",
    "- Menjawab Research Question beserta kesimpulan dan pembahasan\n",
    "\n",
    "Milestone 6 : \n",
    "- Laporan Final \n",
    "- Pembuatan Presentasi dan Poster\n",
    "- Publikasi dalam paper (opsional) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
